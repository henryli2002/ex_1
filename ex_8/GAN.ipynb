{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 设定超参数\n",
    "batch_size = 64\n",
    "learning_rate_g = 0.001\n",
    "learning_rate_d = 0.001\n",
    "epochs = 50\n",
    "image_size = 32\n",
    "latent_dim = 100\n",
    "channels = 3\n",
    "num_classes = 10  # CIFAR10数据集的类别数\n",
    "\n",
    "# 数据集加载器\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 生成器\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
    "        # 全连接层，用于增加维度\n",
    "        self.fc = nn.Linear(num_classes + latent_dim, 256 * 4 * 4)\n",
    "        self.model = nn.Sequential(\n",
    "            # 重塑为4D张量，以匹配ConvTranspose2d层的输入需求\n",
    "            nn.Unflatten(1, (256, 4, 4)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, channels, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        # 将噪声扩展为4D张量\n",
    "        noise = noise.view(noise.size(0), latent_dim, 1, 1)\n",
    "\n",
    "        # 将标签嵌入扩展到与噪声相同的维度\n",
    "        labels = self.label_emb(labels).unsqueeze(-1).unsqueeze(-1)\n",
    "        labels = labels.expand(-1, -1, noise.size(2), noise.size(3))\n",
    "\n",
    "        # 现在可以将噪声和标签合并\n",
    "        gen_input = torch.cat((noise, labels), 1)\n",
    "        gen_input = self.fc(gen_input.view(gen_input.size(0), -1))\n",
    "        out = self.model(gen_input)\n",
    "        return out\n",
    "\n",
    "# 判别器\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
    "        # 修改全连接层的输出维度，使之与卷积层输入匹配\n",
    "        self.fc = nn.Linear(num_classes + 3 * 32 * 32, 128 * 16 * 16)\n",
    "        self.model = nn.Sequential(\n",
    "            # 重塑为适合卷积层的尺寸\n",
    "            nn.Unflatten(1, (128, 16, 16)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        # 将图像和标签结合起来\n",
    "        d_input = torch.cat((x.view(x.size(0), -1), self.label_emb(labels)), -1)\n",
    "        d_input = self.fc(d_input)\n",
    "        out = self.model(d_input)\n",
    "        return out.view(-1, 1).squeeze(1)\n",
    "\n",
    "\n",
    "# 初始化网络并移动到指定的设备上\n",
    "netG = Generator().to(device)\n",
    "netD = Discriminator().to(device)\n",
    "\n",
    "# 损失函数和优化器\n",
    "criterion = nn.BCELoss()\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=learning_rate_g)\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=learning_rate_d)\n",
    "\n",
    "# 训练循环\n",
    "for epoch in range(epochs):\n",
    "    for i, (data, labels) in enumerate(train_loader):\n",
    "        ############################\n",
    "        # (1) 更新判别器网络: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        netD.zero_grad()\n",
    "        # 训练真实数据\n",
    "        real_data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        b_size = real_data.size(0)\n",
    "        label = torch.full((b_size,), 1, dtype=torch.float, device=device)\n",
    "        output = netD(real_data, labels)\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        # 训练生成的假数据\n",
    "        noise = torch.randn(b_size, latent_dim, device=device)\n",
    "        fake_labels = torch.randint(0, num_classes, (b_size,), device=device)\n",
    "        fake = netG(noise, fake_labels)\n",
    "        label.fill_(0)\n",
    "        output = netD(fake.detach(), fake_labels)\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) 更新生成器网络: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(1)  # fake labels are real for generator cost\n",
    "        output = netD(fake, fake_labels)\n",
    "        errG = criterion(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerG.step()\n",
    "\n",
    "        # 打印损失\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, epochs, i, len(train_loader),\n",
    "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "\n",
    "# 保存模型\n",
    "torch.save(netG.state_dict(), 'generator.pth')\n",
    "torch.save(netD.state_dict(), 'discriminator.pth')\n",
    "\n",
    "\n",
    "# 生成新图像\n",
    "num_images_per_class = 10  # 每个类别生成的图片数\n",
    "fake_images = []\n",
    "\n",
    "for class_label in range(num_classes):\n",
    "    # 为每个类别生成相应的标签\n",
    "    labels = torch.full((num_images_per_class,), class_label, dtype=torch.long, device=device)\n",
    "    # 生成噪声\n",
    "    noise = torch.randn(num_images_per_class, latent_dim, 1, 1, device=device)\n",
    "    # 生成图片\n",
    "    with torch.no_grad():\n",
    "        class_fake_images = netG(noise, labels)\n",
    "        fake_images.append(class_fake_images)\n",
    "\n",
    "# 将所有生成的图片合并到一起\n",
    "fake_images = torch.cat(fake_images, dim=0)\n",
    "fake_images = fake_images.detach().cpu()\n",
    "\n",
    "# 显示生成的图片\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Generated Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(fake_images, nrow=num_images_per_class, padding=2, normalize=True).cpu(), (1, 2, 0)))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
