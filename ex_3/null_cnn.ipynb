{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "       \n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128 * 16 * 16, 128) \n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        \n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = x.view(-1, 128 * 16 * 16)  \n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "lr:0.0005,FOLD: 0\n",
      "--------------------------------\n",
      "\n",
      "Valid set: Average loss: 0.8301, Accuracy: 7092/10000 (71%)\n",
      "\n",
      "lr:0.0005,FOLD: 1\n",
      "--------------------------------\n",
      "\n",
      "Valid set: Average loss: 0.9110, Accuracy: 6841/10000 (68%)\n",
      "\n",
      "lr:0.0005,FOLD: 2\n",
      "--------------------------------\n",
      "\n",
      "Valid set: Average loss: 0.8462, Accuracy: 7093/10000 (71%)\n",
      "\n",
      "lr:0.0005,FOLD: 3\n",
      "--------------------------------\n",
      "\n",
      "Valid set: Average loss: 0.8906, Accuracy: 6932/10000 (69%)\n",
      "\n",
      "lr:0.0005,FOLD: 4\n",
      "--------------------------------\n",
      "\n",
      "Valid set: Average loss: 0.8940, Accuracy: 6945/10000 (69%)\n",
      "\n",
      "学习率为：0.0005平均结果：0.69806\n",
      "lr:0.001,FOLD: 0\n",
      "--------------------------------\n",
      "\n",
      "Valid set: Average loss: 0.8045, Accuracy: 7259/10000 (73%)\n",
      "\n",
      "lr:0.001,FOLD: 1\n",
      "--------------------------------\n",
      "\n",
      "Valid set: Average loss: 0.8622, Accuracy: 7189/10000 (72%)\n",
      "\n",
      "lr:0.001,FOLD: 2\n",
      "--------------------------------\n",
      "\n",
      "Valid set: Average loss: 0.8085, Accuracy: 7284/10000 (73%)\n",
      "\n",
      "lr:0.001,FOLD: 3\n",
      "--------------------------------\n",
      "\n",
      "Valid set: Average loss: 0.8562, Accuracy: 7185/10000 (72%)\n",
      "\n",
      "lr:0.001,FOLD: 4\n",
      "--------------------------------\n",
      "\n",
      "Valid set: Average loss: 0.8243, Accuracy: 7284/10000 (73%)\n",
      "\n",
      "学习率为：0.001平均结果：0.7240200000000001\n",
      "lr:0.0015,FOLD: 0\n",
      "--------------------------------\n",
      "\n",
      "Valid set: Average loss: 0.8505, Accuracy: 7204/10000 (72%)\n",
      "\n",
      "lr:0.0015,FOLD: 1\n",
      "--------------------------------\n",
      "\n",
      "Valid set: Average loss: 0.8272, Accuracy: 7402/10000 (74%)\n",
      "\n",
      "lr:0.0015,FOLD: 2\n",
      "--------------------------------\n",
      "\n",
      "Valid set: Average loss: 0.7979, Accuracy: 7453/10000 (75%)\n",
      "\n",
      "lr:0.0015,FOLD: 3\n",
      "--------------------------------\n",
      "\n",
      "Valid set: Average loss: 0.8855, Accuracy: 7205/10000 (72%)\n",
      "\n",
      "lr:0.0015,FOLD: 4\n",
      "--------------------------------\n",
      "\n",
      "Valid set: Average loss: 0.8544, Accuracy: 7366/10000 (74%)\n",
      "\n",
      "学习率为：0.0015平均结果：0.7325999999999999\n",
      "lr:0.002,FOLD: 0\n",
      "--------------------------------\n",
      "\n",
      "Valid set: Average loss: 0.8536, Accuracy: 7292/10000 (73%)\n",
      "\n",
      "lr:0.002,FOLD: 1\n",
      "--------------------------------\n",
      "\n",
      "Valid set: Average loss: 0.8749, Accuracy: 7392/10000 (74%)\n",
      "\n",
      "lr:0.002,FOLD: 2\n",
      "--------------------------------\n",
      "\n",
      "Valid set: Average loss: 0.7828, Accuracy: 7459/10000 (75%)\n",
      "\n",
      "lr:0.002,FOLD: 3\n",
      "--------------------------------\n",
      "\n",
      "Valid set: Average loss: 0.8480, Accuracy: 7390/10000 (74%)\n",
      "\n",
      "lr:0.002,FOLD: 4\n",
      "--------------------------------\n",
      "\n",
      "Valid set: Average loss: 0.8220, Accuracy: 7344/10000 (73%)\n",
      "\n",
      "学习率为：0.002平均结果：0.7375399999999999\n",
      "lr:0.0025,FOLD: 0\n",
      "--------------------------------\n",
      "\n",
      "Valid set: Average loss: 0.8646, Accuracy: 7363/10000 (74%)\n",
      "\n",
      "lr:0.0025,FOLD: 1\n",
      "--------------------------------\n",
      "\n",
      "Valid set: Average loss: 0.9435, Accuracy: 7366/10000 (74%)\n",
      "\n",
      "lr:0.0025,FOLD: 2\n",
      "--------------------------------\n",
      "\n",
      "Valid set: Average loss: 0.8579, Accuracy: 7305/10000 (73%)\n",
      "\n",
      "lr:0.0025,FOLD: 3\n",
      "--------------------------------\n",
      "\n",
      "Valid set: Average loss: 0.9054, Accuracy: 7177/10000 (72%)\n",
      "\n",
      "lr:0.0025,FOLD: 4\n",
      "--------------------------------\n",
      "\n",
      "Valid set: Average loss: 0.9327, Accuracy: 7366/10000 (74%)\n",
      "\n",
      "学习率为：0.0025平均结果：0.7315400000000001\n"
     ]
    }
   ],
   "source": [
    "# k折交叉验证\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "\n",
    "transforms_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.226, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "full_dataset = datasets.CIFAR10('./data/CIFAR10', train=True, download=True, transform=transforms_train)\n",
    "\n",
    "def get_k_fold_data(k, i, dataset):\n",
    "    fold_size = len(dataset) // k\n",
    "    \n",
    "    val_start = i * fold_size\n",
    "    val_end = (i + 1) * fold_size if i < k - 1 else len(dataset)\n",
    "    \n",
    "    val_indices = list(range(val_start, val_end))\n",
    "    train_indices = list(range(0, val_start)) + list(range(val_end, len(dataset)))\n",
    "\n",
    "    return Subset(dataset, train_indices), Subset(dataset, val_indices)\n",
    "\n",
    "\n",
    "def train(lr, train_loader):\n",
    "    # 模型实例化和优化器设置\n",
    "    model = CNN()\n",
    "    optimizer = optim.Adamax(model.parameters(), lr=lr)\n",
    "\n",
    "    # 设备设置\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    # 训练过程\n",
    "    for epoch in range(1, 10):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # 将数据移动到设备上\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = torch.nn.CrossEntropyLoss()(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # 保存模型\n",
    "    torch.save(model.state_dict(), f'./model/NULL_cnn.pt')\n",
    "\n",
    "def valid(valid_loader):\n",
    "    model = CNN()\n",
    "    model.load_state_dict(torch.load(f'./model/NULL_cnn.pt'))\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in valid_loader:\n",
    "           \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(valid_loader.dataset)\n",
    "    print(f'\\nValid set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(valid_loader.dataset)} ({100. * correct / len(valid_loader.dataset):.0f}%)\\n')\n",
    "    return  correct / len(valid_loader.dataset)\n",
    "\n",
    "\n",
    "k_folds = 5\n",
    "for lr_ in range(1, 6):\n",
    "    rate = 0.0\n",
    "    lr = lr_ * 0.0005  #从0.0005到0.0025每隔0.0005进行一次k折交叉验证\n",
    "    for i in range(k_folds):\n",
    "        print(f\"lr:{lr},FOLD: {i}\")\n",
    "        print(\"--------------------------------\")\n",
    "\n",
    "        train_subset, val_subset = get_k_fold_data(k_folds, i, full_dataset)\n",
    "\n",
    "        train_loader = DataLoader(train_subset, batch_size=128, shuffle=True)\n",
    "        valid_loader = DataLoader(val_subset, batch_size=128, shuffle=False)\n",
    "        train(lr, train_loader)\n",
    "        rate += valid(valid_loader)\n",
    "    print(f\"学习率为：{lr}平均结果：{rate / k_folds}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.297033\n",
      "Train Epoch: 1 [640/50000 (1%)]\tLoss: 2.267631\n",
      "Train Epoch: 1 [1280/50000 (3%)]\tLoss: 2.184319\n",
      "Train Epoch: 1 [1920/50000 (4%)]\tLoss: 2.154015\n",
      "Train Epoch: 1 [2560/50000 (5%)]\tLoss: 1.902373\n",
      "Train Epoch: 1 [3200/50000 (6%)]\tLoss: 2.040782\n",
      "Train Epoch: 1 [3840/50000 (8%)]\tLoss: 1.942515\n",
      "Train Epoch: 1 [4480/50000 (9%)]\tLoss: 1.875883\n",
      "Train Epoch: 1 [5120/50000 (10%)]\tLoss: 1.870070\n",
      "Train Epoch: 1 [5760/50000 (12%)]\tLoss: 1.752329\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 1.787758\n",
      "Train Epoch: 1 [7040/50000 (14%)]\tLoss: 1.718637\n",
      "Train Epoch: 1 [7680/50000 (15%)]\tLoss: 1.592201\n",
      "Train Epoch: 1 [8320/50000 (17%)]\tLoss: 1.631913\n",
      "Train Epoch: 1 [8960/50000 (18%)]\tLoss: 1.726522\n",
      "Train Epoch: 1 [9600/50000 (19%)]\tLoss: 1.442886\n",
      "Train Epoch: 1 [10240/50000 (20%)]\tLoss: 1.429687\n",
      "Train Epoch: 1 [10880/50000 (22%)]\tLoss: 1.299579\n",
      "Train Epoch: 1 [11520/50000 (23%)]\tLoss: 1.605687\n",
      "Train Epoch: 1 [12160/50000 (24%)]\tLoss: 1.768157\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.696149\n",
      "Train Epoch: 1 [13440/50000 (27%)]\tLoss: 1.518092\n",
      "Train Epoch: 1 [14080/50000 (28%)]\tLoss: 1.352813\n",
      "Train Epoch: 1 [14720/50000 (29%)]\tLoss: 1.328315\n",
      "Train Epoch: 1 [15360/50000 (31%)]\tLoss: 1.499840\n",
      "Train Epoch: 1 [16000/50000 (32%)]\tLoss: 1.402280\n",
      "Train Epoch: 1 [16640/50000 (33%)]\tLoss: 1.552495\n",
      "Train Epoch: 1 [17280/50000 (35%)]\tLoss: 1.321278\n",
      "Train Epoch: 1 [17920/50000 (36%)]\tLoss: 1.267227\n",
      "Train Epoch: 1 [18560/50000 (37%)]\tLoss: 1.322509\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 1.496685\n",
      "Train Epoch: 1 [19840/50000 (40%)]\tLoss: 1.405542\n",
      "Train Epoch: 1 [20480/50000 (41%)]\tLoss: 1.415231\n",
      "Train Epoch: 1 [21120/50000 (42%)]\tLoss: 1.383424\n",
      "Train Epoch: 1 [21760/50000 (43%)]\tLoss: 1.471054\n",
      "Train Epoch: 1 [22400/50000 (45%)]\tLoss: 1.442191\n",
      "Train Epoch: 1 [23040/50000 (46%)]\tLoss: 1.438810\n",
      "Train Epoch: 1 [23680/50000 (47%)]\tLoss: 1.362579\n",
      "Train Epoch: 1 [24320/50000 (49%)]\tLoss: 1.118653\n",
      "Train Epoch: 1 [24960/50000 (50%)]\tLoss: 1.492690\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.195558\n",
      "Train Epoch: 1 [26240/50000 (52%)]\tLoss: 1.406506\n",
      "Train Epoch: 1 [26880/50000 (54%)]\tLoss: 1.376332\n",
      "Train Epoch: 1 [27520/50000 (55%)]\tLoss: 1.317720\n",
      "Train Epoch: 1 [28160/50000 (56%)]\tLoss: 1.233402\n",
      "Train Epoch: 1 [28800/50000 (58%)]\tLoss: 1.466584\n",
      "Train Epoch: 1 [29440/50000 (59%)]\tLoss: 1.149644\n",
      "Train Epoch: 1 [30080/50000 (60%)]\tLoss: 1.151639\n",
      "Train Epoch: 1 [30720/50000 (61%)]\tLoss: 1.352591\n",
      "Train Epoch: 1 [31360/50000 (63%)]\tLoss: 1.242416\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 1.463546\n",
      "Train Epoch: 1 [32640/50000 (65%)]\tLoss: 1.189016\n",
      "Train Epoch: 1 [33280/50000 (66%)]\tLoss: 1.057315\n",
      "Train Epoch: 1 [33920/50000 (68%)]\tLoss: 1.165733\n",
      "Train Epoch: 1 [34560/50000 (69%)]\tLoss: 1.294473\n",
      "Train Epoch: 1 [35200/50000 (70%)]\tLoss: 1.409683\n",
      "Train Epoch: 1 [35840/50000 (72%)]\tLoss: 1.255603\n",
      "Train Epoch: 1 [36480/50000 (73%)]\tLoss: 1.339401\n",
      "Train Epoch: 1 [37120/50000 (74%)]\tLoss: 1.069043\n",
      "Train Epoch: 1 [37760/50000 (75%)]\tLoss: 1.140121\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.208706\n",
      "Train Epoch: 1 [39040/50000 (78%)]\tLoss: 1.117017\n",
      "Train Epoch: 1 [39680/50000 (79%)]\tLoss: 1.081167\n",
      "Train Epoch: 1 [40320/50000 (81%)]\tLoss: 1.246642\n",
      "Train Epoch: 1 [40960/50000 (82%)]\tLoss: 1.078854\n",
      "Train Epoch: 1 [41600/50000 (83%)]\tLoss: 1.060084\n",
      "Train Epoch: 1 [42240/50000 (84%)]\tLoss: 1.257452\n",
      "Train Epoch: 1 [42880/50000 (86%)]\tLoss: 1.094588\n",
      "Train Epoch: 1 [43520/50000 (87%)]\tLoss: 1.217994\n",
      "Train Epoch: 1 [44160/50000 (88%)]\tLoss: 1.150977\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 1.067328\n",
      "Train Epoch: 1 [45440/50000 (91%)]\tLoss: 1.394630\n",
      "Train Epoch: 1 [46080/50000 (92%)]\tLoss: 1.129275\n",
      "Train Epoch: 1 [46720/50000 (93%)]\tLoss: 1.023079\n",
      "Train Epoch: 1 [47360/50000 (95%)]\tLoss: 1.047884\n",
      "Train Epoch: 1 [48000/50000 (96%)]\tLoss: 1.181531\n",
      "Train Epoch: 1 [48640/50000 (97%)]\tLoss: 1.096675\n",
      "Train Epoch: 1 [49280/50000 (98%)]\tLoss: 1.105028\n",
      "Train Epoch: 1 [49920/50000 (100%)]\tLoss: 1.138814\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.173004\n",
      "Train Epoch: 2 [640/50000 (1%)]\tLoss: 0.943425\n",
      "Train Epoch: 2 [1280/50000 (3%)]\tLoss: 1.185593\n",
      "Train Epoch: 2 [1920/50000 (4%)]\tLoss: 1.148647\n",
      "Train Epoch: 2 [2560/50000 (5%)]\tLoss: 1.412765\n",
      "Train Epoch: 2 [3200/50000 (6%)]\tLoss: 1.126464\n",
      "Train Epoch: 2 [3840/50000 (8%)]\tLoss: 1.116912\n",
      "Train Epoch: 2 [4480/50000 (9%)]\tLoss: 0.955856\n",
      "Train Epoch: 2 [5120/50000 (10%)]\tLoss: 0.999080\n",
      "Train Epoch: 2 [5760/50000 (12%)]\tLoss: 1.019179\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 1.288784\n",
      "Train Epoch: 2 [7040/50000 (14%)]\tLoss: 0.896617\n",
      "Train Epoch: 2 [7680/50000 (15%)]\tLoss: 1.315150\n",
      "Train Epoch: 2 [8320/50000 (17%)]\tLoss: 0.831717\n",
      "Train Epoch: 2 [8960/50000 (18%)]\tLoss: 0.999761\n",
      "Train Epoch: 2 [9600/50000 (19%)]\tLoss: 0.951858\n",
      "Train Epoch: 2 [10240/50000 (20%)]\tLoss: 0.972289\n",
      "Train Epoch: 2 [10880/50000 (22%)]\tLoss: 1.143830\n",
      "Train Epoch: 2 [11520/50000 (23%)]\tLoss: 1.005037\n",
      "Train Epoch: 2 [12160/50000 (24%)]\tLoss: 0.962858\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.008441\n",
      "Train Epoch: 2 [13440/50000 (27%)]\tLoss: 1.015319\n",
      "Train Epoch: 2 [14080/50000 (28%)]\tLoss: 0.671001\n",
      "Train Epoch: 2 [14720/50000 (29%)]\tLoss: 0.867589\n",
      "Train Epoch: 2 [15360/50000 (31%)]\tLoss: 1.113504\n",
      "Train Epoch: 2 [16000/50000 (32%)]\tLoss: 1.188981\n",
      "Train Epoch: 2 [16640/50000 (33%)]\tLoss: 1.148778\n",
      "Train Epoch: 2 [17280/50000 (35%)]\tLoss: 0.888812\n",
      "Train Epoch: 2 [17920/50000 (36%)]\tLoss: 0.803333\n",
      "Train Epoch: 2 [18560/50000 (37%)]\tLoss: 0.978317\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 0.941857\n",
      "Train Epoch: 2 [19840/50000 (40%)]\tLoss: 0.852218\n",
      "Train Epoch: 2 [20480/50000 (41%)]\tLoss: 1.050980\n",
      "Train Epoch: 2 [21120/50000 (42%)]\tLoss: 0.970907\n",
      "Train Epoch: 2 [21760/50000 (43%)]\tLoss: 0.807355\n",
      "Train Epoch: 2 [22400/50000 (45%)]\tLoss: 0.894164\n",
      "Train Epoch: 2 [23040/50000 (46%)]\tLoss: 0.900400\n",
      "Train Epoch: 2 [23680/50000 (47%)]\tLoss: 1.016465\n",
      "Train Epoch: 2 [24320/50000 (49%)]\tLoss: 0.799247\n",
      "Train Epoch: 2 [24960/50000 (50%)]\tLoss: 1.035406\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.021583\n",
      "Train Epoch: 2 [26240/50000 (52%)]\tLoss: 1.054938\n",
      "Train Epoch: 2 [26880/50000 (54%)]\tLoss: 0.998420\n",
      "Train Epoch: 2 [27520/50000 (55%)]\tLoss: 1.096948\n",
      "Train Epoch: 2 [28160/50000 (56%)]\tLoss: 0.864060\n",
      "Train Epoch: 2 [28800/50000 (58%)]\tLoss: 1.133795\n",
      "Train Epoch: 2 [29440/50000 (59%)]\tLoss: 0.937001\n",
      "Train Epoch: 2 [30080/50000 (60%)]\tLoss: 0.753699\n",
      "Train Epoch: 2 [30720/50000 (61%)]\tLoss: 0.663547\n",
      "Train Epoch: 2 [31360/50000 (63%)]\tLoss: 0.788189\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 0.891123\n",
      "Train Epoch: 2 [32640/50000 (65%)]\tLoss: 0.948033\n",
      "Train Epoch: 2 [33280/50000 (66%)]\tLoss: 0.779284\n",
      "Train Epoch: 2 [33920/50000 (68%)]\tLoss: 1.092246\n",
      "Train Epoch: 2 [34560/50000 (69%)]\tLoss: 0.931842\n",
      "Train Epoch: 2 [35200/50000 (70%)]\tLoss: 1.151234\n",
      "Train Epoch: 2 [35840/50000 (72%)]\tLoss: 0.919475\n",
      "Train Epoch: 2 [36480/50000 (73%)]\tLoss: 0.968468\n",
      "Train Epoch: 2 [37120/50000 (74%)]\tLoss: 1.024110\n",
      "Train Epoch: 2 [37760/50000 (75%)]\tLoss: 0.797488\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 0.868817\n",
      "Train Epoch: 2 [39040/50000 (78%)]\tLoss: 0.959726\n",
      "Train Epoch: 2 [39680/50000 (79%)]\tLoss: 0.793439\n",
      "Train Epoch: 2 [40320/50000 (81%)]\tLoss: 0.909761\n",
      "Train Epoch: 2 [40960/50000 (82%)]\tLoss: 0.814630\n",
      "Train Epoch: 2 [41600/50000 (83%)]\tLoss: 0.735528\n",
      "Train Epoch: 2 [42240/50000 (84%)]\tLoss: 0.642445\n",
      "Train Epoch: 2 [42880/50000 (86%)]\tLoss: 0.638184\n",
      "Train Epoch: 2 [43520/50000 (87%)]\tLoss: 0.801785\n",
      "Train Epoch: 2 [44160/50000 (88%)]\tLoss: 0.784817\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 1.031234\n",
      "Train Epoch: 2 [45440/50000 (91%)]\tLoss: 1.011968\n",
      "Train Epoch: 2 [46080/50000 (92%)]\tLoss: 1.095654\n",
      "Train Epoch: 2 [46720/50000 (93%)]\tLoss: 0.810729\n",
      "Train Epoch: 2 [47360/50000 (95%)]\tLoss: 0.914186\n",
      "Train Epoch: 2 [48000/50000 (96%)]\tLoss: 0.837304\n",
      "Train Epoch: 2 [48640/50000 (97%)]\tLoss: 0.770908\n",
      "Train Epoch: 2 [49280/50000 (98%)]\tLoss: 0.965954\n",
      "Train Epoch: 2 [49920/50000 (100%)]\tLoss: 0.645959\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 0.848466\n",
      "Train Epoch: 3 [640/50000 (1%)]\tLoss: 1.020873\n",
      "Train Epoch: 3 [1280/50000 (3%)]\tLoss: 0.910665\n",
      "Train Epoch: 3 [1920/50000 (4%)]\tLoss: 1.027243\n",
      "Train Epoch: 3 [2560/50000 (5%)]\tLoss: 0.622956\n",
      "Train Epoch: 3 [3200/50000 (6%)]\tLoss: 0.747990\n",
      "Train Epoch: 3 [3840/50000 (8%)]\tLoss: 0.597420\n",
      "Train Epoch: 3 [4480/50000 (9%)]\tLoss: 0.969600\n",
      "Train Epoch: 3 [5120/50000 (10%)]\tLoss: 0.837390\n",
      "Train Epoch: 3 [5760/50000 (12%)]\tLoss: 0.897946\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 0.799449\n",
      "Train Epoch: 3 [7040/50000 (14%)]\tLoss: 0.728121\n",
      "Train Epoch: 3 [7680/50000 (15%)]\tLoss: 0.849810\n",
      "Train Epoch: 3 [8320/50000 (17%)]\tLoss: 0.936106\n",
      "Train Epoch: 3 [8960/50000 (18%)]\tLoss: 0.714270\n",
      "Train Epoch: 3 [9600/50000 (19%)]\tLoss: 0.673775\n",
      "Train Epoch: 3 [10240/50000 (20%)]\tLoss: 1.060994\n",
      "Train Epoch: 3 [10880/50000 (22%)]\tLoss: 0.684724\n",
      "Train Epoch: 3 [11520/50000 (23%)]\tLoss: 0.753906\n",
      "Train Epoch: 3 [12160/50000 (24%)]\tLoss: 0.772976\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 0.818759\n",
      "Train Epoch: 3 [13440/50000 (27%)]\tLoss: 0.931941\n",
      "Train Epoch: 3 [14080/50000 (28%)]\tLoss: 0.851403\n",
      "Train Epoch: 3 [14720/50000 (29%)]\tLoss: 1.137846\n",
      "Train Epoch: 3 [15360/50000 (31%)]\tLoss: 1.088771\n",
      "Train Epoch: 3 [16000/50000 (32%)]\tLoss: 0.657771\n",
      "Train Epoch: 3 [16640/50000 (33%)]\tLoss: 0.935771\n",
      "Train Epoch: 3 [17280/50000 (35%)]\tLoss: 0.626881\n",
      "Train Epoch: 3 [17920/50000 (36%)]\tLoss: 0.730847\n",
      "Train Epoch: 3 [18560/50000 (37%)]\tLoss: 0.742714\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 0.793230\n",
      "Train Epoch: 3 [19840/50000 (40%)]\tLoss: 0.949742\n",
      "Train Epoch: 3 [20480/50000 (41%)]\tLoss: 0.785080\n",
      "Train Epoch: 3 [21120/50000 (42%)]\tLoss: 0.693974\n",
      "Train Epoch: 3 [21760/50000 (43%)]\tLoss: 0.581467\n",
      "Train Epoch: 3 [22400/50000 (45%)]\tLoss: 0.804410\n",
      "Train Epoch: 3 [23040/50000 (46%)]\tLoss: 0.762232\n",
      "Train Epoch: 3 [23680/50000 (47%)]\tLoss: 0.807443\n",
      "Train Epoch: 3 [24320/50000 (49%)]\tLoss: 0.880990\n",
      "Train Epoch: 3 [24960/50000 (50%)]\tLoss: 0.816172\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.816259\n",
      "Train Epoch: 3 [26240/50000 (52%)]\tLoss: 0.854015\n",
      "Train Epoch: 3 [26880/50000 (54%)]\tLoss: 0.785050\n",
      "Train Epoch: 3 [27520/50000 (55%)]\tLoss: 0.947473\n",
      "Train Epoch: 3 [28160/50000 (56%)]\tLoss: 0.755119\n",
      "Train Epoch: 3 [28800/50000 (58%)]\tLoss: 0.683771\n",
      "Train Epoch: 3 [29440/50000 (59%)]\tLoss: 0.968687\n",
      "Train Epoch: 3 [30080/50000 (60%)]\tLoss: 0.804597\n",
      "Train Epoch: 3 [30720/50000 (61%)]\tLoss: 0.918521\n",
      "Train Epoch: 3 [31360/50000 (63%)]\tLoss: 0.660628\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 0.777499\n",
      "Train Epoch: 3 [32640/50000 (65%)]\tLoss: 0.871033\n",
      "Train Epoch: 3 [33280/50000 (66%)]\tLoss: 0.793042\n",
      "Train Epoch: 3 [33920/50000 (68%)]\tLoss: 0.707527\n",
      "Train Epoch: 3 [34560/50000 (69%)]\tLoss: 0.801799\n",
      "Train Epoch: 3 [35200/50000 (70%)]\tLoss: 0.860947\n",
      "Train Epoch: 3 [35840/50000 (72%)]\tLoss: 0.984613\n",
      "Train Epoch: 3 [36480/50000 (73%)]\tLoss: 0.873513\n",
      "Train Epoch: 3 [37120/50000 (74%)]\tLoss: 0.798075\n",
      "Train Epoch: 3 [37760/50000 (75%)]\tLoss: 0.927756\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 0.872744\n",
      "Train Epoch: 3 [39040/50000 (78%)]\tLoss: 0.851705\n",
      "Train Epoch: 3 [39680/50000 (79%)]\tLoss: 0.781850\n",
      "Train Epoch: 3 [40320/50000 (81%)]\tLoss: 1.016193\n",
      "Train Epoch: 3 [40960/50000 (82%)]\tLoss: 0.809961\n",
      "Train Epoch: 3 [41600/50000 (83%)]\tLoss: 0.770615\n",
      "Train Epoch: 3 [42240/50000 (84%)]\tLoss: 0.732608\n",
      "Train Epoch: 3 [42880/50000 (86%)]\tLoss: 0.863305\n",
      "Train Epoch: 3 [43520/50000 (87%)]\tLoss: 0.835830\n",
      "Train Epoch: 3 [44160/50000 (88%)]\tLoss: 0.707973\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 0.767737\n",
      "Train Epoch: 3 [45440/50000 (91%)]\tLoss: 0.818652\n",
      "Train Epoch: 3 [46080/50000 (92%)]\tLoss: 0.981949\n",
      "Train Epoch: 3 [46720/50000 (93%)]\tLoss: 0.783537\n",
      "Train Epoch: 3 [47360/50000 (95%)]\tLoss: 0.562596\n",
      "Train Epoch: 3 [48000/50000 (96%)]\tLoss: 0.663578\n",
      "Train Epoch: 3 [48640/50000 (97%)]\tLoss: 0.817420\n",
      "Train Epoch: 3 [49280/50000 (98%)]\tLoss: 0.628602\n",
      "Train Epoch: 3 [49920/50000 (100%)]\tLoss: 0.908816\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.914179\n",
      "Train Epoch: 4 [640/50000 (1%)]\tLoss: 0.588743\n",
      "Train Epoch: 4 [1280/50000 (3%)]\tLoss: 0.839314\n",
      "Train Epoch: 4 [1920/50000 (4%)]\tLoss: 0.838605\n",
      "Train Epoch: 4 [2560/50000 (5%)]\tLoss: 0.652330\n",
      "Train Epoch: 4 [3200/50000 (6%)]\tLoss: 0.689348\n",
      "Train Epoch: 4 [3840/50000 (8%)]\tLoss: 0.436123\n",
      "Train Epoch: 4 [4480/50000 (9%)]\tLoss: 0.513777\n",
      "Train Epoch: 4 [5120/50000 (10%)]\tLoss: 0.643232\n",
      "Train Epoch: 4 [5760/50000 (12%)]\tLoss: 0.437457\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 0.715607\n",
      "Train Epoch: 4 [7040/50000 (14%)]\tLoss: 0.545206\n",
      "Train Epoch: 4 [7680/50000 (15%)]\tLoss: 0.889279\n",
      "Train Epoch: 4 [8320/50000 (17%)]\tLoss: 0.704500\n",
      "Train Epoch: 4 [8960/50000 (18%)]\tLoss: 0.576794\n",
      "Train Epoch: 4 [9600/50000 (19%)]\tLoss: 0.839294\n",
      "Train Epoch: 4 [10240/50000 (20%)]\tLoss: 0.651503\n",
      "Train Epoch: 4 [10880/50000 (22%)]\tLoss: 0.723982\n",
      "Train Epoch: 4 [11520/50000 (23%)]\tLoss: 0.714980\n",
      "Train Epoch: 4 [12160/50000 (24%)]\tLoss: 0.712170\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 0.755901\n",
      "Train Epoch: 4 [13440/50000 (27%)]\tLoss: 0.762823\n",
      "Train Epoch: 4 [14080/50000 (28%)]\tLoss: 0.647789\n",
      "Train Epoch: 4 [14720/50000 (29%)]\tLoss: 0.650793\n",
      "Train Epoch: 4 [15360/50000 (31%)]\tLoss: 0.534913\n",
      "Train Epoch: 4 [16000/50000 (32%)]\tLoss: 0.796335\n",
      "Train Epoch: 4 [16640/50000 (33%)]\tLoss: 0.979896\n",
      "Train Epoch: 4 [17280/50000 (35%)]\tLoss: 0.707817\n",
      "Train Epoch: 4 [17920/50000 (36%)]\tLoss: 0.698282\n",
      "Train Epoch: 4 [18560/50000 (37%)]\tLoss: 0.639985\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 0.754451\n",
      "Train Epoch: 4 [19840/50000 (40%)]\tLoss: 0.915562\n",
      "Train Epoch: 4 [20480/50000 (41%)]\tLoss: 0.544925\n",
      "Train Epoch: 4 [21120/50000 (42%)]\tLoss: 0.766272\n",
      "Train Epoch: 4 [21760/50000 (43%)]\tLoss: 0.712640\n",
      "Train Epoch: 4 [22400/50000 (45%)]\tLoss: 0.861085\n",
      "Train Epoch: 4 [23040/50000 (46%)]\tLoss: 0.559305\n",
      "Train Epoch: 4 [23680/50000 (47%)]\tLoss: 0.558054\n",
      "Train Epoch: 4 [24320/50000 (49%)]\tLoss: 0.597077\n",
      "Train Epoch: 4 [24960/50000 (50%)]\tLoss: 0.593727\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 0.558289\n",
      "Train Epoch: 4 [26240/50000 (52%)]\tLoss: 0.924050\n",
      "Train Epoch: 4 [26880/50000 (54%)]\tLoss: 0.660353\n",
      "Train Epoch: 4 [27520/50000 (55%)]\tLoss: 0.834273\n",
      "Train Epoch: 4 [28160/50000 (56%)]\tLoss: 0.739291\n",
      "Train Epoch: 4 [28800/50000 (58%)]\tLoss: 0.698726\n",
      "Train Epoch: 4 [29440/50000 (59%)]\tLoss: 0.625258\n",
      "Train Epoch: 4 [30080/50000 (60%)]\tLoss: 0.509872\n",
      "Train Epoch: 4 [30720/50000 (61%)]\tLoss: 0.696606\n",
      "Train Epoch: 4 [31360/50000 (63%)]\tLoss: 0.674002\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 0.415489\n",
      "Train Epoch: 4 [32640/50000 (65%)]\tLoss: 0.782031\n",
      "Train Epoch: 4 [33280/50000 (66%)]\tLoss: 0.545021\n",
      "Train Epoch: 4 [33920/50000 (68%)]\tLoss: 0.786378\n",
      "Train Epoch: 4 [34560/50000 (69%)]\tLoss: 0.858671\n",
      "Train Epoch: 4 [35200/50000 (70%)]\tLoss: 0.719623\n",
      "Train Epoch: 4 [35840/50000 (72%)]\tLoss: 0.505949\n",
      "Train Epoch: 4 [36480/50000 (73%)]\tLoss: 0.681613\n",
      "Train Epoch: 4 [37120/50000 (74%)]\tLoss: 0.557422\n",
      "Train Epoch: 4 [37760/50000 (75%)]\tLoss: 0.685728\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 0.631630\n",
      "Train Epoch: 4 [39040/50000 (78%)]\tLoss: 0.438764\n",
      "Train Epoch: 4 [39680/50000 (79%)]\tLoss: 0.501331\n",
      "Train Epoch: 4 [40320/50000 (81%)]\tLoss: 0.838221\n",
      "Train Epoch: 4 [40960/50000 (82%)]\tLoss: 0.540139\n",
      "Train Epoch: 4 [41600/50000 (83%)]\tLoss: 0.721462\n",
      "Train Epoch: 4 [42240/50000 (84%)]\tLoss: 0.766752\n",
      "Train Epoch: 4 [42880/50000 (86%)]\tLoss: 0.595911\n",
      "Train Epoch: 4 [43520/50000 (87%)]\tLoss: 0.695953\n",
      "Train Epoch: 4 [44160/50000 (88%)]\tLoss: 0.660919\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 0.777796\n",
      "Train Epoch: 4 [45440/50000 (91%)]\tLoss: 0.894944\n",
      "Train Epoch: 4 [46080/50000 (92%)]\tLoss: 0.377547\n",
      "Train Epoch: 4 [46720/50000 (93%)]\tLoss: 0.624268\n",
      "Train Epoch: 4 [47360/50000 (95%)]\tLoss: 0.404800\n",
      "Train Epoch: 4 [48000/50000 (96%)]\tLoss: 0.511786\n",
      "Train Epoch: 4 [48640/50000 (97%)]\tLoss: 0.977664\n",
      "Train Epoch: 4 [49280/50000 (98%)]\tLoss: 0.735782\n",
      "Train Epoch: 4 [49920/50000 (100%)]\tLoss: 0.579053\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.703271\n",
      "Train Epoch: 5 [640/50000 (1%)]\tLoss: 0.586065\n",
      "Train Epoch: 5 [1280/50000 (3%)]\tLoss: 0.528895\n",
      "Train Epoch: 5 [1920/50000 (4%)]\tLoss: 0.528199\n",
      "Train Epoch: 5 [2560/50000 (5%)]\tLoss: 0.648148\n",
      "Train Epoch: 5 [3200/50000 (6%)]\tLoss: 0.651936\n",
      "Train Epoch: 5 [3840/50000 (8%)]\tLoss: 0.525073\n",
      "Train Epoch: 5 [4480/50000 (9%)]\tLoss: 0.529951\n",
      "Train Epoch: 5 [5120/50000 (10%)]\tLoss: 0.465639\n",
      "Train Epoch: 5 [5760/50000 (12%)]\tLoss: 0.562321\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 0.590977\n",
      "Train Epoch: 5 [7040/50000 (14%)]\tLoss: 0.467881\n",
      "Train Epoch: 5 [7680/50000 (15%)]\tLoss: 0.578028\n",
      "Train Epoch: 5 [8320/50000 (17%)]\tLoss: 0.593407\n",
      "Train Epoch: 5 [8960/50000 (18%)]\tLoss: 0.644202\n",
      "Train Epoch: 5 [9600/50000 (19%)]\tLoss: 0.633056\n",
      "Train Epoch: 5 [10240/50000 (20%)]\tLoss: 0.674206\n",
      "Train Epoch: 5 [10880/50000 (22%)]\tLoss: 0.444779\n",
      "Train Epoch: 5 [11520/50000 (23%)]\tLoss: 0.431536\n",
      "Train Epoch: 5 [12160/50000 (24%)]\tLoss: 0.517665\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 0.775851\n",
      "Train Epoch: 5 [13440/50000 (27%)]\tLoss: 0.623318\n",
      "Train Epoch: 5 [14080/50000 (28%)]\tLoss: 0.393990\n",
      "Train Epoch: 5 [14720/50000 (29%)]\tLoss: 0.547122\n",
      "Train Epoch: 5 [15360/50000 (31%)]\tLoss: 0.477189\n",
      "Train Epoch: 5 [16000/50000 (32%)]\tLoss: 0.489445\n",
      "Train Epoch: 5 [16640/50000 (33%)]\tLoss: 0.635769\n",
      "Train Epoch: 5 [17280/50000 (35%)]\tLoss: 0.626235\n",
      "Train Epoch: 5 [17920/50000 (36%)]\tLoss: 0.579400\n",
      "Train Epoch: 5 [18560/50000 (37%)]\tLoss: 0.656755\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 0.708257\n",
      "Train Epoch: 5 [19840/50000 (40%)]\tLoss: 0.492780\n",
      "Train Epoch: 5 [20480/50000 (41%)]\tLoss: 0.390072\n",
      "Train Epoch: 5 [21120/50000 (42%)]\tLoss: 0.393147\n",
      "Train Epoch: 5 [21760/50000 (43%)]\tLoss: 0.584222\n",
      "Train Epoch: 5 [22400/50000 (45%)]\tLoss: 0.391012\n",
      "Train Epoch: 5 [23040/50000 (46%)]\tLoss: 0.593343\n",
      "Train Epoch: 5 [23680/50000 (47%)]\tLoss: 0.738748\n",
      "Train Epoch: 5 [24320/50000 (49%)]\tLoss: 0.731432\n",
      "Train Epoch: 5 [24960/50000 (50%)]\tLoss: 0.443459\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.407933\n",
      "Train Epoch: 5 [26240/50000 (52%)]\tLoss: 0.598491\n",
      "Train Epoch: 5 [26880/50000 (54%)]\tLoss: 0.539815\n",
      "Train Epoch: 5 [27520/50000 (55%)]\tLoss: 0.611469\n",
      "Train Epoch: 5 [28160/50000 (56%)]\tLoss: 0.852093\n",
      "Train Epoch: 5 [28800/50000 (58%)]\tLoss: 0.590926\n",
      "Train Epoch: 5 [29440/50000 (59%)]\tLoss: 0.421841\n",
      "Train Epoch: 5 [30080/50000 (60%)]\tLoss: 0.673964\n",
      "Train Epoch: 5 [30720/50000 (61%)]\tLoss: 0.547999\n",
      "Train Epoch: 5 [31360/50000 (63%)]\tLoss: 0.457519\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 0.363152\n",
      "Train Epoch: 5 [32640/50000 (65%)]\tLoss: 0.481417\n",
      "Train Epoch: 5 [33280/50000 (66%)]\tLoss: 0.479913\n",
      "Train Epoch: 5 [33920/50000 (68%)]\tLoss: 0.548790\n",
      "Train Epoch: 5 [34560/50000 (69%)]\tLoss: 0.520267\n",
      "Train Epoch: 5 [35200/50000 (70%)]\tLoss: 0.713694\n",
      "Train Epoch: 5 [35840/50000 (72%)]\tLoss: 0.654012\n",
      "Train Epoch: 5 [36480/50000 (73%)]\tLoss: 0.712053\n",
      "Train Epoch: 5 [37120/50000 (74%)]\tLoss: 0.574504\n",
      "Train Epoch: 5 [37760/50000 (75%)]\tLoss: 0.549431\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 0.407009\n",
      "Train Epoch: 5 [39040/50000 (78%)]\tLoss: 0.644255\n",
      "Train Epoch: 5 [39680/50000 (79%)]\tLoss: 0.636888\n",
      "Train Epoch: 5 [40320/50000 (81%)]\tLoss: 0.619466\n",
      "Train Epoch: 5 [40960/50000 (82%)]\tLoss: 0.476376\n",
      "Train Epoch: 5 [41600/50000 (83%)]\tLoss: 0.543752\n",
      "Train Epoch: 5 [42240/50000 (84%)]\tLoss: 0.675940\n",
      "Train Epoch: 5 [42880/50000 (86%)]\tLoss: 0.686527\n",
      "Train Epoch: 5 [43520/50000 (87%)]\tLoss: 0.564202\n",
      "Train Epoch: 5 [44160/50000 (88%)]\tLoss: 0.608162\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 0.599440\n",
      "Train Epoch: 5 [45440/50000 (91%)]\tLoss: 0.558506\n",
      "Train Epoch: 5 [46080/50000 (92%)]\tLoss: 0.483356\n",
      "Train Epoch: 5 [46720/50000 (93%)]\tLoss: 0.417271\n",
      "Train Epoch: 5 [47360/50000 (95%)]\tLoss: 0.465417\n",
      "Train Epoch: 5 [48000/50000 (96%)]\tLoss: 0.429181\n",
      "Train Epoch: 5 [48640/50000 (97%)]\tLoss: 0.674280\n",
      "Train Epoch: 5 [49280/50000 (98%)]\tLoss: 0.468878\n",
      "Train Epoch: 5 [49920/50000 (100%)]\tLoss: 0.487550\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.409683\n",
      "Train Epoch: 6 [640/50000 (1%)]\tLoss: 0.312862\n",
      "Train Epoch: 6 [1280/50000 (3%)]\tLoss: 0.595888\n",
      "Train Epoch: 6 [1920/50000 (4%)]\tLoss: 0.358353\n",
      "Train Epoch: 6 [2560/50000 (5%)]\tLoss: 0.311416\n",
      "Train Epoch: 6 [3200/50000 (6%)]\tLoss: 0.431386\n",
      "Train Epoch: 6 [3840/50000 (8%)]\tLoss: 0.477312\n",
      "Train Epoch: 6 [4480/50000 (9%)]\tLoss: 0.577020\n",
      "Train Epoch: 6 [5120/50000 (10%)]\tLoss: 0.428734\n",
      "Train Epoch: 6 [5760/50000 (12%)]\tLoss: 0.360787\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 0.340315\n",
      "Train Epoch: 6 [7040/50000 (14%)]\tLoss: 0.385939\n",
      "Train Epoch: 6 [7680/50000 (15%)]\tLoss: 0.379163\n",
      "Train Epoch: 6 [8320/50000 (17%)]\tLoss: 0.391991\n",
      "Train Epoch: 6 [8960/50000 (18%)]\tLoss: 0.732465\n",
      "Train Epoch: 6 [9600/50000 (19%)]\tLoss: 0.364149\n",
      "Train Epoch: 6 [10240/50000 (20%)]\tLoss: 0.415554\n",
      "Train Epoch: 6 [10880/50000 (22%)]\tLoss: 0.360674\n",
      "Train Epoch: 6 [11520/50000 (23%)]\tLoss: 0.460303\n",
      "Train Epoch: 6 [12160/50000 (24%)]\tLoss: 0.388705\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.256642\n",
      "Train Epoch: 6 [13440/50000 (27%)]\tLoss: 0.488667\n",
      "Train Epoch: 6 [14080/50000 (28%)]\tLoss: 0.494458\n",
      "Train Epoch: 6 [14720/50000 (29%)]\tLoss: 0.323074\n",
      "Train Epoch: 6 [15360/50000 (31%)]\tLoss: 0.315338\n",
      "Train Epoch: 6 [16000/50000 (32%)]\tLoss: 0.462380\n",
      "Train Epoch: 6 [16640/50000 (33%)]\tLoss: 0.472503\n",
      "Train Epoch: 6 [17280/50000 (35%)]\tLoss: 0.511781\n",
      "Train Epoch: 6 [17920/50000 (36%)]\tLoss: 0.640697\n",
      "Train Epoch: 6 [18560/50000 (37%)]\tLoss: 0.509501\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 0.406924\n",
      "Train Epoch: 6 [19840/50000 (40%)]\tLoss: 0.293643\n",
      "Train Epoch: 6 [20480/50000 (41%)]\tLoss: 0.369649\n",
      "Train Epoch: 6 [21120/50000 (42%)]\tLoss: 0.407188\n",
      "Train Epoch: 6 [21760/50000 (43%)]\tLoss: 0.487332\n",
      "Train Epoch: 6 [22400/50000 (45%)]\tLoss: 0.566242\n",
      "Train Epoch: 6 [23040/50000 (46%)]\tLoss: 0.519407\n",
      "Train Epoch: 6 [23680/50000 (47%)]\tLoss: 0.538813\n",
      "Train Epoch: 6 [24320/50000 (49%)]\tLoss: 0.475129\n",
      "Train Epoch: 6 [24960/50000 (50%)]\tLoss: 0.569148\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.224477\n",
      "Train Epoch: 6 [26240/50000 (52%)]\tLoss: 0.472934\n",
      "Train Epoch: 6 [26880/50000 (54%)]\tLoss: 0.556252\n",
      "Train Epoch: 6 [27520/50000 (55%)]\tLoss: 0.450656\n",
      "Train Epoch: 6 [28160/50000 (56%)]\tLoss: 0.363528\n",
      "Train Epoch: 6 [28800/50000 (58%)]\tLoss: 0.271496\n",
      "Train Epoch: 6 [29440/50000 (59%)]\tLoss: 0.441981\n",
      "Train Epoch: 6 [30080/50000 (60%)]\tLoss: 0.442916\n",
      "Train Epoch: 6 [30720/50000 (61%)]\tLoss: 0.438047\n",
      "Train Epoch: 6 [31360/50000 (63%)]\tLoss: 0.530434\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 0.728633\n",
      "Train Epoch: 6 [32640/50000 (65%)]\tLoss: 0.569512\n",
      "Train Epoch: 6 [33280/50000 (66%)]\tLoss: 0.391487\n",
      "Train Epoch: 6 [33920/50000 (68%)]\tLoss: 0.623640\n",
      "Train Epoch: 6 [34560/50000 (69%)]\tLoss: 0.325114\n",
      "Train Epoch: 6 [35200/50000 (70%)]\tLoss: 0.549638\n",
      "Train Epoch: 6 [35840/50000 (72%)]\tLoss: 0.417054\n",
      "Train Epoch: 6 [36480/50000 (73%)]\tLoss: 0.339585\n",
      "Train Epoch: 6 [37120/50000 (74%)]\tLoss: 0.477674\n",
      "Train Epoch: 6 [37760/50000 (75%)]\tLoss: 0.499473\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 0.627471\n",
      "Train Epoch: 6 [39040/50000 (78%)]\tLoss: 0.594215\n",
      "Train Epoch: 6 [39680/50000 (79%)]\tLoss: 0.513235\n",
      "Train Epoch: 6 [40320/50000 (81%)]\tLoss: 0.309026\n",
      "Train Epoch: 6 [40960/50000 (82%)]\tLoss: 0.555316\n",
      "Train Epoch: 6 [41600/50000 (83%)]\tLoss: 0.442037\n",
      "Train Epoch: 6 [42240/50000 (84%)]\tLoss: 0.456269\n",
      "Train Epoch: 6 [42880/50000 (86%)]\tLoss: 0.378237\n",
      "Train Epoch: 6 [43520/50000 (87%)]\tLoss: 0.506702\n",
      "Train Epoch: 6 [44160/50000 (88%)]\tLoss: 0.399725\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 0.431284\n",
      "Train Epoch: 6 [45440/50000 (91%)]\tLoss: 0.284312\n",
      "Train Epoch: 6 [46080/50000 (92%)]\tLoss: 0.398224\n",
      "Train Epoch: 6 [46720/50000 (93%)]\tLoss: 0.496838\n",
      "Train Epoch: 6 [47360/50000 (95%)]\tLoss: 0.676214\n",
      "Train Epoch: 6 [48000/50000 (96%)]\tLoss: 0.460893\n",
      "Train Epoch: 6 [48640/50000 (97%)]\tLoss: 0.508524\n",
      "Train Epoch: 6 [49280/50000 (98%)]\tLoss: 0.619124\n",
      "Train Epoch: 6 [49920/50000 (100%)]\tLoss: 0.481121\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.335452\n",
      "Train Epoch: 7 [640/50000 (1%)]\tLoss: 0.352007\n",
      "Train Epoch: 7 [1280/50000 (3%)]\tLoss: 0.440043\n",
      "Train Epoch: 7 [1920/50000 (4%)]\tLoss: 0.366837\n",
      "Train Epoch: 7 [2560/50000 (5%)]\tLoss: 0.454739\n",
      "Train Epoch: 7 [3200/50000 (6%)]\tLoss: 0.289080\n",
      "Train Epoch: 7 [3840/50000 (8%)]\tLoss: 0.321812\n",
      "Train Epoch: 7 [4480/50000 (9%)]\tLoss: 0.504688\n",
      "Train Epoch: 7 [5120/50000 (10%)]\tLoss: 0.640892\n",
      "Train Epoch: 7 [5760/50000 (12%)]\tLoss: 0.367564\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 0.382176\n",
      "Train Epoch: 7 [7040/50000 (14%)]\tLoss: 0.557508\n",
      "Train Epoch: 7 [7680/50000 (15%)]\tLoss: 0.489020\n",
      "Train Epoch: 7 [8320/50000 (17%)]\tLoss: 0.276299\n",
      "Train Epoch: 7 [8960/50000 (18%)]\tLoss: 0.360012\n",
      "Train Epoch: 7 [9600/50000 (19%)]\tLoss: 0.566606\n",
      "Train Epoch: 7 [10240/50000 (20%)]\tLoss: 0.357695\n",
      "Train Epoch: 7 [10880/50000 (22%)]\tLoss: 0.281812\n",
      "Train Epoch: 7 [11520/50000 (23%)]\tLoss: 0.498020\n",
      "Train Epoch: 7 [12160/50000 (24%)]\tLoss: 0.578144\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.282969\n",
      "Train Epoch: 7 [13440/50000 (27%)]\tLoss: 0.443940\n",
      "Train Epoch: 7 [14080/50000 (28%)]\tLoss: 0.388262\n",
      "Train Epoch: 7 [14720/50000 (29%)]\tLoss: 0.417702\n",
      "Train Epoch: 7 [15360/50000 (31%)]\tLoss: 0.552243\n",
      "Train Epoch: 7 [16000/50000 (32%)]\tLoss: 0.371208\n",
      "Train Epoch: 7 [16640/50000 (33%)]\tLoss: 0.453718\n",
      "Train Epoch: 7 [17280/50000 (35%)]\tLoss: 0.238982\n",
      "Train Epoch: 7 [17920/50000 (36%)]\tLoss: 0.418373\n",
      "Train Epoch: 7 [18560/50000 (37%)]\tLoss: 0.357104\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 0.407537\n",
      "Train Epoch: 7 [19840/50000 (40%)]\tLoss: 0.238524\n",
      "Train Epoch: 7 [20480/50000 (41%)]\tLoss: 0.416662\n",
      "Train Epoch: 7 [21120/50000 (42%)]\tLoss: 0.353747\n",
      "Train Epoch: 7 [21760/50000 (43%)]\tLoss: 0.394785\n",
      "Train Epoch: 7 [22400/50000 (45%)]\tLoss: 0.577572\n",
      "Train Epoch: 7 [23040/50000 (46%)]\tLoss: 0.316136\n",
      "Train Epoch: 7 [23680/50000 (47%)]\tLoss: 0.365599\n",
      "Train Epoch: 7 [24320/50000 (49%)]\tLoss: 0.357081\n",
      "Train Epoch: 7 [24960/50000 (50%)]\tLoss: 0.564160\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.370344\n",
      "Train Epoch: 7 [26240/50000 (52%)]\tLoss: 0.488330\n",
      "Train Epoch: 7 [26880/50000 (54%)]\tLoss: 0.301894\n",
      "Train Epoch: 7 [27520/50000 (55%)]\tLoss: 0.398525\n",
      "Train Epoch: 7 [28160/50000 (56%)]\tLoss: 0.283450\n",
      "Train Epoch: 7 [28800/50000 (58%)]\tLoss: 0.208318\n",
      "Train Epoch: 7 [29440/50000 (59%)]\tLoss: 0.368657\n",
      "Train Epoch: 7 [30080/50000 (60%)]\tLoss: 0.375894\n",
      "Train Epoch: 7 [30720/50000 (61%)]\tLoss: 0.311665\n",
      "Train Epoch: 7 [31360/50000 (63%)]\tLoss: 0.470113\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 0.402919\n",
      "Train Epoch: 7 [32640/50000 (65%)]\tLoss: 0.488830\n",
      "Train Epoch: 7 [33280/50000 (66%)]\tLoss: 0.368601\n",
      "Train Epoch: 7 [33920/50000 (68%)]\tLoss: 0.354024\n",
      "Train Epoch: 7 [34560/50000 (69%)]\tLoss: 0.341361\n",
      "Train Epoch: 7 [35200/50000 (70%)]\tLoss: 0.524347\n",
      "Train Epoch: 7 [35840/50000 (72%)]\tLoss: 0.324806\n",
      "Train Epoch: 7 [36480/50000 (73%)]\tLoss: 0.441706\n",
      "Train Epoch: 7 [37120/50000 (74%)]\tLoss: 0.400048\n",
      "Train Epoch: 7 [37760/50000 (75%)]\tLoss: 0.454334\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.312888\n",
      "Train Epoch: 7 [39040/50000 (78%)]\tLoss: 0.405029\n",
      "Train Epoch: 7 [39680/50000 (79%)]\tLoss: 0.415898\n",
      "Train Epoch: 7 [40320/50000 (81%)]\tLoss: 0.614220\n",
      "Train Epoch: 7 [40960/50000 (82%)]\tLoss: 0.527331\n",
      "Train Epoch: 7 [41600/50000 (83%)]\tLoss: 0.265171\n",
      "Train Epoch: 7 [42240/50000 (84%)]\tLoss: 0.654968\n",
      "Train Epoch: 7 [42880/50000 (86%)]\tLoss: 0.208505\n",
      "Train Epoch: 7 [43520/50000 (87%)]\tLoss: 0.464062\n",
      "Train Epoch: 7 [44160/50000 (88%)]\tLoss: 0.522623\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 0.399470\n",
      "Train Epoch: 7 [45440/50000 (91%)]\tLoss: 0.286064\n",
      "Train Epoch: 7 [46080/50000 (92%)]\tLoss: 0.450309\n",
      "Train Epoch: 7 [46720/50000 (93%)]\tLoss: 0.371454\n",
      "Train Epoch: 7 [47360/50000 (95%)]\tLoss: 0.291539\n",
      "Train Epoch: 7 [48000/50000 (96%)]\tLoss: 0.238639\n",
      "Train Epoch: 7 [48640/50000 (97%)]\tLoss: 0.241971\n",
      "Train Epoch: 7 [49280/50000 (98%)]\tLoss: 0.423033\n",
      "Train Epoch: 7 [49920/50000 (100%)]\tLoss: 0.238830\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.276007\n",
      "Train Epoch: 8 [640/50000 (1%)]\tLoss: 0.333707\n",
      "Train Epoch: 8 [1280/50000 (3%)]\tLoss: 0.331774\n",
      "Train Epoch: 8 [1920/50000 (4%)]\tLoss: 0.201749\n",
      "Train Epoch: 8 [2560/50000 (5%)]\tLoss: 0.250516\n",
      "Train Epoch: 8 [3200/50000 (6%)]\tLoss: 0.493089\n",
      "Train Epoch: 8 [3840/50000 (8%)]\tLoss: 0.240800\n",
      "Train Epoch: 8 [4480/50000 (9%)]\tLoss: 0.328236\n",
      "Train Epoch: 8 [5120/50000 (10%)]\tLoss: 0.328668\n",
      "Train Epoch: 8 [5760/50000 (12%)]\tLoss: 0.382771\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 0.406329\n",
      "Train Epoch: 8 [7040/50000 (14%)]\tLoss: 0.351195\n",
      "Train Epoch: 8 [7680/50000 (15%)]\tLoss: 0.337775\n",
      "Train Epoch: 8 [8320/50000 (17%)]\tLoss: 0.354310\n",
      "Train Epoch: 8 [8960/50000 (18%)]\tLoss: 0.268499\n",
      "Train Epoch: 8 [9600/50000 (19%)]\tLoss: 0.181156\n",
      "Train Epoch: 8 [10240/50000 (20%)]\tLoss: 0.317336\n",
      "Train Epoch: 8 [10880/50000 (22%)]\tLoss: 0.272412\n",
      "Train Epoch: 8 [11520/50000 (23%)]\tLoss: 0.277182\n",
      "Train Epoch: 8 [12160/50000 (24%)]\tLoss: 0.437296\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.353938\n",
      "Train Epoch: 8 [13440/50000 (27%)]\tLoss: 0.255687\n",
      "Train Epoch: 8 [14080/50000 (28%)]\tLoss: 0.341827\n",
      "Train Epoch: 8 [14720/50000 (29%)]\tLoss: 0.326146\n",
      "Train Epoch: 8 [15360/50000 (31%)]\tLoss: 0.383930\n",
      "Train Epoch: 8 [16000/50000 (32%)]\tLoss: 0.549345\n",
      "Train Epoch: 8 [16640/50000 (33%)]\tLoss: 0.342927\n",
      "Train Epoch: 8 [17280/50000 (35%)]\tLoss: 0.236205\n",
      "Train Epoch: 8 [17920/50000 (36%)]\tLoss: 0.359438\n",
      "Train Epoch: 8 [18560/50000 (37%)]\tLoss: 0.324468\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 0.368824\n",
      "Train Epoch: 8 [19840/50000 (40%)]\tLoss: 0.214249\n",
      "Train Epoch: 8 [20480/50000 (41%)]\tLoss: 0.256725\n",
      "Train Epoch: 8 [21120/50000 (42%)]\tLoss: 0.404510\n",
      "Train Epoch: 8 [21760/50000 (43%)]\tLoss: 0.188452\n",
      "Train Epoch: 8 [22400/50000 (45%)]\tLoss: 0.233682\n",
      "Train Epoch: 8 [23040/50000 (46%)]\tLoss: 0.175903\n",
      "Train Epoch: 8 [23680/50000 (47%)]\tLoss: 0.327580\n",
      "Train Epoch: 8 [24320/50000 (49%)]\tLoss: 0.349530\n",
      "Train Epoch: 8 [24960/50000 (50%)]\tLoss: 0.400258\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.265026\n",
      "Train Epoch: 8 [26240/50000 (52%)]\tLoss: 0.456783\n",
      "Train Epoch: 8 [26880/50000 (54%)]\tLoss: 0.291327\n",
      "Train Epoch: 8 [27520/50000 (55%)]\tLoss: 0.322501\n",
      "Train Epoch: 8 [28160/50000 (56%)]\tLoss: 0.236262\n",
      "Train Epoch: 8 [28800/50000 (58%)]\tLoss: 0.374740\n",
      "Train Epoch: 8 [29440/50000 (59%)]\tLoss: 0.219334\n",
      "Train Epoch: 8 [30080/50000 (60%)]\tLoss: 0.217440\n",
      "Train Epoch: 8 [30720/50000 (61%)]\tLoss: 0.331095\n",
      "Train Epoch: 8 [31360/50000 (63%)]\tLoss: 0.403457\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 0.360422\n",
      "Train Epoch: 8 [32640/50000 (65%)]\tLoss: 0.298831\n",
      "Train Epoch: 8 [33280/50000 (66%)]\tLoss: 0.279249\n",
      "Train Epoch: 8 [33920/50000 (68%)]\tLoss: 0.258867\n",
      "Train Epoch: 8 [34560/50000 (69%)]\tLoss: 0.352697\n",
      "Train Epoch: 8 [35200/50000 (70%)]\tLoss: 0.291812\n",
      "Train Epoch: 8 [35840/50000 (72%)]\tLoss: 0.411432\n",
      "Train Epoch: 8 [36480/50000 (73%)]\tLoss: 0.366335\n",
      "Train Epoch: 8 [37120/50000 (74%)]\tLoss: 0.330176\n",
      "Train Epoch: 8 [37760/50000 (75%)]\tLoss: 0.199655\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.288974\n",
      "Train Epoch: 8 [39040/50000 (78%)]\tLoss: 0.315252\n",
      "Train Epoch: 8 [39680/50000 (79%)]\tLoss: 0.408208\n",
      "Train Epoch: 8 [40320/50000 (81%)]\tLoss: 0.382868\n",
      "Train Epoch: 8 [40960/50000 (82%)]\tLoss: 0.228728\n",
      "Train Epoch: 8 [41600/50000 (83%)]\tLoss: 0.438653\n",
      "Train Epoch: 8 [42240/50000 (84%)]\tLoss: 0.260718\n",
      "Train Epoch: 8 [42880/50000 (86%)]\tLoss: 0.350455\n",
      "Train Epoch: 8 [43520/50000 (87%)]\tLoss: 0.363164\n",
      "Train Epoch: 8 [44160/50000 (88%)]\tLoss: 0.214293\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 0.282804\n",
      "Train Epoch: 8 [45440/50000 (91%)]\tLoss: 0.325472\n",
      "Train Epoch: 8 [46080/50000 (92%)]\tLoss: 0.229571\n",
      "Train Epoch: 8 [46720/50000 (93%)]\tLoss: 0.391878\n",
      "Train Epoch: 8 [47360/50000 (95%)]\tLoss: 0.165097\n",
      "Train Epoch: 8 [48000/50000 (96%)]\tLoss: 0.358419\n",
      "Train Epoch: 8 [48640/50000 (97%)]\tLoss: 0.489468\n",
      "Train Epoch: 8 [49280/50000 (98%)]\tLoss: 0.173767\n",
      "Train Epoch: 8 [49920/50000 (100%)]\tLoss: 0.284962\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.281187\n",
      "Train Epoch: 9 [640/50000 (1%)]\tLoss: 0.270671\n",
      "Train Epoch: 9 [1280/50000 (3%)]\tLoss: 0.137463\n",
      "Train Epoch: 9 [1920/50000 (4%)]\tLoss: 0.160761\n",
      "Train Epoch: 9 [2560/50000 (5%)]\tLoss: 0.114587\n",
      "Train Epoch: 9 [3200/50000 (6%)]\tLoss: 0.223322\n",
      "Train Epoch: 9 [3840/50000 (8%)]\tLoss: 0.285709\n",
      "Train Epoch: 9 [4480/50000 (9%)]\tLoss: 0.280199\n",
      "Train Epoch: 9 [5120/50000 (10%)]\tLoss: 0.334474\n",
      "Train Epoch: 9 [5760/50000 (12%)]\tLoss: 0.187986\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 0.291053\n",
      "Train Epoch: 9 [7040/50000 (14%)]\tLoss: 0.203610\n",
      "Train Epoch: 9 [7680/50000 (15%)]\tLoss: 0.151603\n",
      "Train Epoch: 9 [8320/50000 (17%)]\tLoss: 0.250103\n",
      "Train Epoch: 9 [8960/50000 (18%)]\tLoss: 0.171010\n",
      "Train Epoch: 9 [9600/50000 (19%)]\tLoss: 0.155674\n",
      "Train Epoch: 9 [10240/50000 (20%)]\tLoss: 0.210651\n",
      "Train Epoch: 9 [10880/50000 (22%)]\tLoss: 0.260038\n",
      "Train Epoch: 9 [11520/50000 (23%)]\tLoss: 0.212056\n",
      "Train Epoch: 9 [12160/50000 (24%)]\tLoss: 0.206731\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.129362\n",
      "Train Epoch: 9 [13440/50000 (27%)]\tLoss: 0.251658\n",
      "Train Epoch: 9 [14080/50000 (28%)]\tLoss: 0.295002\n",
      "Train Epoch: 9 [14720/50000 (29%)]\tLoss: 0.415669\n",
      "Train Epoch: 9 [15360/50000 (31%)]\tLoss: 0.253754\n",
      "Train Epoch: 9 [16000/50000 (32%)]\tLoss: 0.212202\n",
      "Train Epoch: 9 [16640/50000 (33%)]\tLoss: 0.166505\n",
      "Train Epoch: 9 [17280/50000 (35%)]\tLoss: 0.184377\n",
      "Train Epoch: 9 [17920/50000 (36%)]\tLoss: 0.103274\n",
      "Train Epoch: 9 [18560/50000 (37%)]\tLoss: 0.232830\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 0.290165\n",
      "Train Epoch: 9 [19840/50000 (40%)]\tLoss: 0.202759\n",
      "Train Epoch: 9 [20480/50000 (41%)]\tLoss: 0.124207\n",
      "Train Epoch: 9 [21120/50000 (42%)]\tLoss: 0.303380\n",
      "Train Epoch: 9 [21760/50000 (43%)]\tLoss: 0.133481\n",
      "Train Epoch: 9 [22400/50000 (45%)]\tLoss: 0.172983\n",
      "Train Epoch: 9 [23040/50000 (46%)]\tLoss: 0.227240\n",
      "Train Epoch: 9 [23680/50000 (47%)]\tLoss: 0.163527\n",
      "Train Epoch: 9 [24320/50000 (49%)]\tLoss: 0.220977\n",
      "Train Epoch: 9 [24960/50000 (50%)]\tLoss: 0.179793\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.520966\n",
      "Train Epoch: 9 [26240/50000 (52%)]\tLoss: 0.192258\n",
      "Train Epoch: 9 [26880/50000 (54%)]\tLoss: 0.140996\n",
      "Train Epoch: 9 [27520/50000 (55%)]\tLoss: 0.549063\n",
      "Train Epoch: 9 [28160/50000 (56%)]\tLoss: 0.215732\n",
      "Train Epoch: 9 [28800/50000 (58%)]\tLoss: 0.179796\n",
      "Train Epoch: 9 [29440/50000 (59%)]\tLoss: 0.263359\n",
      "Train Epoch: 9 [30080/50000 (60%)]\tLoss: 0.077861\n",
      "Train Epoch: 9 [30720/50000 (61%)]\tLoss: 0.275012\n",
      "Train Epoch: 9 [31360/50000 (63%)]\tLoss: 0.206749\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 0.325113\n",
      "Train Epoch: 9 [32640/50000 (65%)]\tLoss: 0.471472\n",
      "Train Epoch: 9 [33280/50000 (66%)]\tLoss: 0.339685\n",
      "Train Epoch: 9 [33920/50000 (68%)]\tLoss: 0.260712\n",
      "Train Epoch: 9 [34560/50000 (69%)]\tLoss: 0.097526\n",
      "Train Epoch: 9 [35200/50000 (70%)]\tLoss: 0.343086\n",
      "Train Epoch: 9 [35840/50000 (72%)]\tLoss: 0.362223\n",
      "Train Epoch: 9 [36480/50000 (73%)]\tLoss: 0.183221\n",
      "Train Epoch: 9 [37120/50000 (74%)]\tLoss: 0.244819\n",
      "Train Epoch: 9 [37760/50000 (75%)]\tLoss: 0.292096\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.477697\n",
      "Train Epoch: 9 [39040/50000 (78%)]\tLoss: 0.260527\n",
      "Train Epoch: 9 [39680/50000 (79%)]\tLoss: 0.340127\n",
      "Train Epoch: 9 [40320/50000 (81%)]\tLoss: 0.359437\n",
      "Train Epoch: 9 [40960/50000 (82%)]\tLoss: 0.268541\n",
      "Train Epoch: 9 [41600/50000 (83%)]\tLoss: 0.297447\n",
      "Train Epoch: 9 [42240/50000 (84%)]\tLoss: 0.317698\n",
      "Train Epoch: 9 [42880/50000 (86%)]\tLoss: 0.419399\n",
      "Train Epoch: 9 [43520/50000 (87%)]\tLoss: 0.265052\n",
      "Train Epoch: 9 [44160/50000 (88%)]\tLoss: 0.303898\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 0.314258\n",
      "Train Epoch: 9 [45440/50000 (91%)]\tLoss: 0.292816\n",
      "Train Epoch: 9 [46080/50000 (92%)]\tLoss: 0.390151\n",
      "Train Epoch: 9 [46720/50000 (93%)]\tLoss: 0.171090\n",
      "Train Epoch: 9 [47360/50000 (95%)]\tLoss: 0.101725\n",
      "Train Epoch: 9 [48000/50000 (96%)]\tLoss: 0.233927\n",
      "Train Epoch: 9 [48640/50000 (97%)]\tLoss: 0.197704\n",
      "Train Epoch: 9 [49280/50000 (98%)]\tLoss: 0.263742\n",
      "Train Epoch: 9 [49920/50000 (100%)]\tLoss: 0.194828\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 数据加载和预处理\n",
    "transforms_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.226, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    datasets.CIFAR10('./data/CIFAR10', train=True, download=True, transform=transforms_train),\n",
    "    batch_size=64, shuffle=True)\n",
    "\n",
    "def train():\n",
    "    # 模型实例化和优化器设置\n",
    "    model = CNN()\n",
    "    optimizer = optim.Adamax(model.parameters(), lr=0.002)\n",
    "\n",
    "    # 设备设置\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    # 训练过程\n",
    "    for epoch in range(1, 10):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # 将数据移动到设备上\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = torch.nn.CrossEntropyLoss()(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "\n",
    "    # 保存模型\n",
    "    torch.save(model.state_dict(), f'./model/NULL_cnn.pt')\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "\n",
      "Test set: Average loss: 0.9285, Accuracy: 7524/10000 (75%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test.py\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 数据加载\n",
    "transforms_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.226, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    datasets.CIFAR10('./data/CIFAR10', train=False, download=True, transform=transforms_train),\n",
    "    batch_size=1000, shuffle=True)\n",
    "\n",
    "def test():\n",
    "    model = CNN()\n",
    "    model.load_state_dict(torch.load(f'./model/NULL_cnn.pt'))\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)\\n')\n",
    "test()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
